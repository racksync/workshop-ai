# Session 6: Open-WebUI ‡πÅ‡∏•‡∏∞ Ollama

<div class="text-center">
  <img src="../assets/images/ollama-webui.png" alt="Ollama and Open-WebUI" width="700" />
</div>

## üîç ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

Open-WebUI ‡πÅ‡∏•‡∏∞ Ollama ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (LLMs) ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á‡∏û‡∏≤‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå‡πÄ‡∏ä‡πà‡∏ô ChatGPT ‡∏´‡∏£‡∏∑‡∏≠ Claude API ‡πÉ‡∏ô‡πÄ‡∏ã‡∏™‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Open-WebUI ‡πÅ‡∏•‡∏∞ Ollama ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô LLMs ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å

## üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡∏õ‡∏ï‡πå‡∏Ç‡∏≠‡∏á Open-WebUI ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡πÄ‡∏ß‡πá‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLMs
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Ollama ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô LLMs ‡πÅ‡∏ö‡∏ö local
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Ollama API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏≠‡∏∑‡πà‡∏ô
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ custom endpoints
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ Open-WebUI ‡πÅ‡∏•‡∏∞ Ollama ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á

## üìö ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤

### 1. ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Open-WebUI

Open-WebUI (‡πÄ‡∏î‡∏¥‡∏°‡∏ä‡∏∑‡πà‡∏≠ Ollama Web UI) ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏ö‡∏ö open-source ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Ollama ‡πÅ‡∏•‡∏∞ ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö AI ‡πÑ‡∏î‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡∏ö‡∏£‡∏≤‡∏ß‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö ChatGPT

#### 1.1 ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Open-WebUI

- **‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢**: ‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡πÅ‡∏ö‡∏ö‡πÅ‡∏ä‡∏ó‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö ChatGPT
- **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•**: ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏ö‡∏ô Ollama
- **‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤**: ‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
- **‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å**: ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ
- **‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ multi-modal
- **‡∏£‡∏∞‡∏ö‡∏ö prompt templates**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï prompts ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ã‡πâ‡∏≥
- **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•**: ‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô temperature ‡πÅ‡∏•‡∏∞ context length
- **‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API**: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö endpoints ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å Ollama

#### 1.2 ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Open-WebUI

1. **‡∏ü‡∏£‡∏µ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô Open Source**: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤
2. **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß**: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å
3. **‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô**: ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î‡πÑ‡∏î‡πâ
4. **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•**: ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
5. **‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢**: ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏≤‡∏Å‡∏ô‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

#### 1.3 Use Cases ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

- **Personal AI Assistant**: ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£**: ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏π‡∏á
- **‡∏£‡∏∞‡∏ö‡∏ö offline**: ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï
- **‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö**: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö prompts ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ
- **‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏à‡∏±‡∏¢**: ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡∏≠‡∏á LLMs ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£

### 2. ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Open-WebUI

#### 2.1 ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô

‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Open-WebUI ‡πÅ‡∏•‡∏∞ Ollama ‡∏î‡πâ‡∏ß‡∏¢ docker-compose ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

- Docker ‡πÅ‡∏•‡∏∞ Docker Compose ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ RAM ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 8GB (‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ)
- ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10GB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö image ‡πÅ‡∏•‡∏∞ volume

#### 2.2 ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢ Docker Compose

```mermaid
graph TD
    subgraph "Docker Environment"
        OW[Open-WebUI Container] -->|‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö| O[Ollama Container]
        OW -->|‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•| OWV[open-webui-data Volume]
        O -->|‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•| OV[ollama-data Volume]
    end
    
    subgraph "Network"
        N[ai-network]
        OW --- N
        O --- N
    end
    
    U[‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ] -->|‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ú‡πà‡∏≤‡∏ô PORT 3000| OW
    API[External API] -.->|‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°| OW
```

‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `docker-compose.yml` ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```yaml
version: '3.8'

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    restart: always
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434/api
      - OPENAI_API_KEY=${OPENAI_API_KEY:-} # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-} # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
      - PORT=8080
      - HOST=0.0.0.0
    ports:
      - "3000:8080"
    depends_on:
      - ollama
    networks:
      - ai-network

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: always
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "11434:11434"
    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ GPU NVIDIA, ‡∏õ‡∏•‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    networks:
      - ai-network

networks:
  ai-network:
    driver: bridge

volumes:
  open-webui-data:
  ollama-data:
```

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á .env file ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö API keys (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
echo "OPENAI_API_KEY=your-api-key-here" > .env

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£
docker-compose up -d

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
docker-compose ps

# ‡∏î‡∏π‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏à‡∏≤‡∏Å service
docker-compose logs -f open-webui
docker-compose logs -f ollama

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: llama3)
docker-compose exec ollama ollama pull llama3

# ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£
docker-compose down

# ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏•‡∏ö volumes (‡∏£‡∏∞‡∏ß‡∏±‡∏á: ‡∏à‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
docker-compose down -v
```

‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á Open-WebUI ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà http://localhost:3000 ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà services ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß

### 3. ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Ollama

```mermaid
flowchart LR
    A[Ollama] --> B[‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞]
    B --> C[‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö Local]
    B --> D[‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•]
    B --> E[GPU Acceleration]
    B --> F[CLI & API]
    B --> G[Modelfiles]
    B --> H[‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏ö‡∏≤]
    
    A --> I[‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô]
    I --> J[‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î/‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•]
    I --> K[‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•]
    I --> L[‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•]
    I --> M[API Integration]
```

Ollama ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (LLMs) ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏î‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á

#### 3.1 ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Ollama

- **‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö Local**: ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå
- **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÄ‡∏ä‡πà‡∏ô Llama 3, Mistral, Phi, Vicuna ‡∏Ø‡∏•‡∏Ø
- **GPU Acceleration**: ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏à‡∏≤‡∏Å GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
- **CLI & API**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô Command Line ‡πÅ‡∏•‡∏∞ RESTful API
- **Modelfiles**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏≠‡∏ô‡∏ü‡∏¥‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
- **‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏ö‡∏≤**: ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á

#### 3.2 ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama

##### macOS

```bash
brew install ollama
```

##### Linux

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

##### Windows

‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å [https://ollama.com/download](https://ollama.com/download)

##### Docker

```bash
docker pull ollama/ollama
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

#### 3.3 ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Ollama ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

##### ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

```bash
# Pull ‡πÇ‡∏°‡πÄ‡∏î‡∏•
ollama pull llama3

# Chat ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
ollama run llama3

# ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ
ollama run mistral
ollama run phi
```

##### ‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ

```bash
ollama list
```

##### ‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•

```bash
ollama rm llama3
```

### 4. Ollama API

Ollama ‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö RESTful API ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM ‡∏à‡∏≤‡∏Å‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ API ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏û‡∏≠‡∏£‡πå‡∏ï 11434 ‡πÇ‡∏î‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô

#### 4.1 ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô API

API ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏¥‡πà‡∏° Ollama ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

#### 4.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ API ‡∏î‡πâ‡∏ß‡∏¢ curl

##### API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Chat Completion

```bash
curl -X POST http://localhost:11434/api/chat -d '{
  "model": "llama3",
  "messages": [
    { "role": "user", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?" }
  ]
}'
```

##### API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Generation

```bash
curl -X POST http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢",
  "stream": false
}'
```

##### API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•

```bash
curl http://localhost:11434/api/tags
```

#### 4.3 ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ API ‡∏î‡πâ‡∏ß‡∏¢ Python

```python
import requests
import json

# Chat Completion
response = requests.post(
    "http://localhost:11434/api/chat",
    json={
        "model": "llama3",
        "messages": [
            {"role": "user", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?"}
        ]
    }
)

print(response.json()["message"]["content"])

# Generation (‡πÅ‡∏ö‡∏ö stream)
response = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "llama3",
        "prompt": "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢",
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        data = json.loads(line)
        print(data.get("response", ""), end="", flush=True)
        if data.get("done"):
            print()
```

#### 4.4 ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ API ‡∏î‡πâ‡∏ß‡∏¢ Node.js

```javascript
const axios = require('axios');

// Chat Completion
async function chatWithOllama() {
  try {
    const response = await axios.post('http://localhost:11434/api/chat', {
      model: 'llama3',
      messages: [
        { role: 'user', content: '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?' }
      ]
    });
    
    console.log(response.data.message.content);
  } catch (error) {
    console.error('Error:', error);
  }
}

chatWithOllama();

// Generation (‡πÅ‡∏ö‡∏ö stream)
async function generateWithOllama() {
  try {
    const response = await axios.post('http://localhost:11434/api/generate', {
      model: 'llama3',
      prompt: '‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢',
      stream: true
    }, {
      responseType: 'stream'
    });
    
    response.data.on('data', chunk => {
      try {
        const lines = chunk.toString().split('\n').filter(line => line.trim() !== '');
        for (const line of lines) {
          const data = JSON.parse(line);
          process.stdout.write(data.response || '');
        }
      } catch (e) {
        console.error('Error parsing chunk:', e);
      }
    });
  } catch (error) {
    console.error('Error:', error);
  }
}

generateWithOllama();
```

### 5. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ Modelfiles

Modelfiles ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô Ollama ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

#### 5.1 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Modelfile

```
FROM llama3
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
SYSTEM """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏ó‡∏µ‡πà‡∏ä‡∏≤‡∏ç‡∏â‡∏•‡∏≤‡∏î ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á"""
```

‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ PARAMETER ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÉ‡∏ô OpenAI API ‡πÅ‡∏•‡∏∞ Gemini API ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏™‡∏ä‡∏±‡∏ô 5 ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Modelfile ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢

#### 5.2 ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß

1. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Modelfile:

```bash
echo 'FROM llama3
PARAMETER temperature 0.7
SYSTEM "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç"' > Modelfile
```

2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å Modelfile:

```bash
ollama create python-assistant -f Modelfile
```

3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô:

```bash
ollama run python-assistant
```

#### 5.3 ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏î‡πâ

| ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥ |
|------------|----------|---------|
| `temperature` | ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå (0 = ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô, 2 = ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå‡∏™‡∏π‡∏á) | 0.8 |
| `top_p` | Nucleus sampling: ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô | 0.9 |
| `top_k` | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ | 40 |
| `repeat_penalty` | ‡∏ö‡∏ó‡∏•‡∏á‡πÇ‡∏ó‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥ | 1.1 |
| `seed` | ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏° | 0 |
| `num_ctx` | ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß context ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î | ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• |
| `num_gpu` | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô GPU layers | ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå |
| `num_thread` | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô CPU threads | ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå |

### 6. ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Custom Endpoints ‡πÉ‡∏ô Open-WebUI

Open-WebUI ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö endpoints ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å Ollama ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö API ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô OpenAI, Anthropic, ‡∏´‡∏£‡∏∑‡∏≠ Engines ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ

#### 6.1 ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° Custom Endpoint

1. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà Open-WebUI ‡πÅ‡∏•‡∏∞‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤ Settings
2. ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà "Models & Endpoints"
3. ‡∏Ñ‡∏•‡∏¥‡∏Å "Add Endpoint"
4. ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Endpoint:
   - Name: ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á endpoint
   - Endpoint URL: URL ‡∏Ç‡∏≠‡∏á API
   - API Key: ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
   - Models: ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà endpoint ‡∏ô‡∏µ‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

#### 6.2 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Custom Endpoint

##### OpenAI-compatible API

```
Name: LocalAI
Endpoint URL: http://localhost:8080/v1
API Key: (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà LocalAI ‡∏Å‡∏≥‡∏´‡∏ô‡∏î)
Models: gpt-3.5-turbo, gpt-4 (‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà LocalAI ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
```

##### Anthropic API

```
Name: Anthropic
Endpoint URL: https://api.anthropic.com
API Key: (API key ‡∏à‡∏≤‡∏Å Anthropic)
Models: claude-3-opus-20240229, claude-3-sonnet-20240229
```

#### 6.3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á Custom Endpoints

- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô**: ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö API ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≤‡∏á‡πÜ
- **‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö**: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÉ‡∏ô‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
- **Fallback**: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ endpoint ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠ endpoint ‡∏´‡∏•‡∏±‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
- **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ endpoint ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### 7. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Gemini API ‡∏Å‡∏±‡∏ö Open-WebUI

Gemini API ‡πÄ‡∏õ‡πá‡∏ô API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏•‡∏∞ multimodal AI ‡∏à‡∏≤‡∏Å Google ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ Gemini ‡∏à‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö Open-WebUI

#### 7.1 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Gemini API

- **Multimodal**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤
- **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢**: ‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏ô‡∏≤‡∏î ‡πÄ‡∏ä‡πà‡∏ô Gemini Pro, Gemini Ultra
- **Function Calling**: ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å
- **‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ
- **‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÑ‡∏î‡πâ**: ‡∏°‡∏µ‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤‡∏ü‡∏£‡∏µ ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≠ token ‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö provider ‡∏£‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô

#### 7.2 ‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö API Key

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà [Google AI Studio](https://aistudio.google.com/)
2. ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏±‡∏ç‡∏ä‡∏µ Google ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
3. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà "Get API key" ‡∏´‡∏£‡∏∑‡∏≠ "API Keys" ‡πÉ‡∏ô‡πÄ‡∏°‡∏ô‡∏π
4. ‡∏™‡∏£‡πâ‡∏≤‡∏á API key ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢

#### 7.3 ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Gemini API ‡∏Å‡∏±‡∏ö Open-WebUI

##### 7.3.1 ‡πÄ‡∏û‡∏¥‡πà‡∏° Gemini ‡πÄ‡∏õ‡πá‡∏ô Custom Endpoint ‡πÉ‡∏ô Open-WebUI

1. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà Open-WebUI ‡πÅ‡∏•‡∏∞‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤ Settings
2. ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà "Models & Endpoints"
3. ‡∏Ñ‡∏•‡∏¥‡∏Å "Add Endpoint"
4. ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Endpoint:
   - Name: Gemini
   - Endpoint Type: Google Vertex AI ‡∏´‡∏£‡∏∑‡∏≠ OpenAI-Compatible (‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏£‡∏∏‡πà‡∏ô‡∏Ç‡∏≠‡∏á Open-WebUI)
   - API Key: ‡πÉ‡∏™‡πà API key ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å Google AI Studio
   - Models: gemini-pro, gemini-pro-vision (‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ)

> **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏£‡∏∏‡πà‡∏ô‡∏Ç‡∏≠‡∏á Open-WebUI ‡∏≠‡∏≤‡∏à‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Proxy API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å Gemini API format ‡πÄ‡∏õ‡πá‡∏ô OpenAI-compatible format

##### 7.3.2 ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Proxy API (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Proxy API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Gemini API ‡∏Å‡∏±‡∏ö Open-WebUI ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢:

```javascript
// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Proxy API ‡∏î‡πâ‡∏ß‡∏¢ Express
const express = require('express');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const app = express();
app.use(express.json());

// ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Gemini API
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

app.post('/v1/chat/completions', async (req, res) => {
  try {
    const { messages, model, temperature = 0.7 } = req.body;
    const geminiModel = genAI.getGenerativeModel({ model: model === 'gemini-pro-vision' ? 'gemini-pro-vision' : 'gemini-pro' });
    
    // ‡πÅ‡∏õ‡∏•‡∏á OpenAI messages format ‡πÄ‡∏õ‡πá‡∏ô Gemini format
    const geminiMessages = [];
    for (const msg of messages) {
      if (msg.role === 'system') {
        // ‡πÉ‡∏™‡πà system message ‡πÄ‡∏õ‡πá‡∏ô user message ‡πÅ‡∏£‡∏Å
        geminiMessages.push({ role: 'user', parts: [{ text: msg.content }] });
        geminiMessages.push({ role: 'model', parts: [{ text: '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡∏â‡∏±‡∏ô‡∏à‡∏∞‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ' }] });
      } else {
        geminiMessages.push({ 
          role: msg.role === 'assistant' ? 'model' : 'user', 
          parts: [{ text: msg.content }] 
        });
      }
    }
    
    const result = await geminiModel.generateContent({
      contents: geminiMessages,
      generationConfig: {
        temperature: temperature,
      }
    });
    
    // ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô OpenAI format
    res.json({
      id: 'chatcmpl-' + Date.now(),
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: model,
      choices: [{
        index: 0,
        message: {
          role: 'assistant',
          content: result.response.text(),
        },
        finish_reason: 'stop'
      }],
      usage: {
        prompt_tokens: -1,
        completion_tokens: -1,
        total_tokens: -1
      }
    });
  } catch (error) {
    console.error('Error:', error);
    res.status(500).json({ error: error.message });
  }
});

app.listen(3100, () => {
  console.log('Gemini Proxy API running on port 3100');
});
```

##### 7.3.3 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Gemini API ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å Open-WebUI:

```python
import google.generativeai as genai
import os

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
model = genai.GenerativeModel('gemini-pro')

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
chat = model.start_chat(history=[])

# ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö
response = chat.send_message("‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢")
print(response.text)

# ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
response = chat.send_message("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢")
print(response.text)
```

#### 7.4 ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Gemini API ‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û

Gemini Pro Vision ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö LLM ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤:

```python
import google.generativeai as genai
import os
import PIL.Image

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
model = genai.GenerativeModel('gemini-pro-vision')

# ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
image = PIL.Image.open('thai_food.jpg')

# ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
response = model.generate_content(["‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á", image])
print(response.text)
```

#### 7.5 ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ Gemini API

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**:
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ
- ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤‡∏ü‡∏£‡∏µ
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ multimodal ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• text-only
- ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤**:
- ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ proxy middleware ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Open-WebUI
- ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß context ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
- ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Google

### 8. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô: Ollama, Open-WebUI ‡πÅ‡∏•‡∏∞ Gemini API

```mermaid
graph TB
    subgraph "Local Environment"
        A[Ollama] --> B[Local Models]
        C[Open-WebUI] --> A
        C --> D[Custom Prompts]
        C --> E[Chat History]
    end
    
    subgraph "Cloud Services"
        F[Gemini API] --> G[Vision Capabilities]
        F --> H[Advanced Knowledge]
    end
    
    C --> F
    
    U[User] --> C
    C --> U
```

‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ Ollama, Open-WebUI ‡πÅ‡∏•‡∏∞ Gemini API ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏™‡∏π‡∏á ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:

- **Ollama**: ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• local ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß
- **Open-WebUI**: ‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
- **Gemini API**: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô

‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏ó‡∏µ‡πà:
1. ‡πÉ‡∏ä‡πâ Ollama+llama3 ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏ö‡∏ö offline
2. ‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á Gemini Pro Vision ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
3. ‡πÉ‡∏ä‡πâ Open-WebUI ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö

## üõ†Ô∏è Workshop: ‡∏™‡∏£‡πâ‡∏≤‡∏á AI Assistant ‡πÅ‡∏ö‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏î‡πâ‡∏ß‡∏¢ Open-WebUI ‡πÅ‡∏•‡∏∞ Ollama

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ

1. ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 8GB (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 16GB+ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà)
2. Docker ‡πÅ‡∏•‡∏∞ Docker Compose
3. ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏™‡∏Å‡πå‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 5-10GB (‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ)

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

1. **‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°**

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå:

```bash
mkdir ai-assistant
cd ai-assistant
```

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå docker-compose.yml:

```yaml
version: '3.8'

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434/api
    ports:
      - 3000:8080
    restart: always
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    volumes:
      - ollama:/root/.ollama
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  ollama:
  open-webui:
```

‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ GPU NVIDIA ‡πÉ‡∏´‡πâ‡∏•‡∏ö‡∏™‡πà‡∏ß‡∏ô `deploy` ‡∏≠‡∏≠‡∏Å

2. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö**

```bash
docker-compose up -d
```

3. **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•**

```bash
# ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà container
docker exec -it ollama /bin/bash

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏ä‡πà‡∏ô llama3)
ollama pull llama3

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
ollama pull mistral
ollama pull phi

# ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å container
exit
```

4. **‡∏™‡∏£‡πâ‡∏≤‡∏á Assistant ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß**

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Modelfile:

```bash
cat > thai-assistant.modelfile << 'EOF'
FROM llama3

# ‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 4096

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î system prompt
SYSTEM """
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏î‡πâ‡∏≤‡∏ô ‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î 
‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° 
‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÅ‡∏à‡πâ‡∏á‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏≤‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à
‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏ú‡∏π‡πâ‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÉ‡∏´‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
‡πÅ‡∏•‡∏∞‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î
"""
EOF

docker exec -it ollama ollama create thai-assistant -f thai-assistant.modelfile
```

5. **‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Open-WebUI**

- ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ß‡πá‡∏ö‡∏ö‡∏£‡∏≤‡∏ß‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÑ‡∏õ‡∏ó‡∏µ‡πà http://localhost:3000
- ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á)
- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• thai-assistant ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö AI

6. **‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt Templates**

- ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Settings > Prompt Templates
- ‡∏Ñ‡∏•‡∏¥‡∏Å "New Template"
- ‡∏™‡∏£‡πâ‡∏≤‡∏á template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î:
  - Title: "‡πÇ‡∏Ñ‡πâ‡∏î Python"
  - Content: "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö{task}. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û."
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å template ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

7. **‡πÄ‡∏û‡∏¥‡πà‡∏° OpenAI API ‡πÄ‡∏õ‡πá‡∏ô Custom Endpoint (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ API key)**

- ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Settings > Models & Endpoints
- ‡∏Ñ‡∏•‡∏¥‡∏Å "Add Endpoint"
- ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
  - Name: OpenAI
  - Endpoint URL: https://api.openai.com/v1
  - API Key: (‡πÉ‡∏™‡πà API key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
  - Models: gpt-3.5-turbo, gpt-4 (‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á)
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• OpenAI ‡∏ú‡πà‡∏≤‡∏ô Open-WebUI

8. **‡πÄ‡∏û‡∏¥‡πà‡∏° Gemini API ‡πÄ‡∏õ‡πá‡∏ô Custom Endpoint**

- ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Settings > Models & Endpoints
- ‡∏Ñ‡∏•‡∏¥‡∏Å "Add Endpoint"
- ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
  - Name: Gemini
  - Endpoint URL: [URL ‡∏Ç‡∏≠‡∏á Gemini Proxy API ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà Open-WebUI ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö]
  - API Key: [‡πÉ‡∏™‡πà Gemini API key]
  - Models: gemini-pro, gemini-pro-vision
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

9. **‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt Template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini Vision**

- ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Settings > Prompt Templates
- ‡∏Ñ‡∏•‡∏¥‡∏Å "New Template"
- ‡∏™‡∏£‡πâ‡∏≤‡∏á template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:
  - Title: "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û"
  - Content: "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏â‡∏±‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å template ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û

## üìö ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- [Open-WebUI GitHub Repository](https://github.com/open-webui/open-webui)
- [Ollama Documentation](https://ollama.com/docs)
- [Ollama GitHub Repository](https://github.com/ollama/ollama)
- [LLM Models Library](https://ollama.com/library)
- [Modelfile Documentation](https://github.com/ollama/ollama/blob/main/docs/modelfile.md)
- [Open-WebUI Docker Image](https://github.com/open-webui/open-webui/pkgs/container/open-webui)
- [Community Extensions for Ollama](https://github.com/ollama/ollama/tree/main/docs/extensions)
- [Google AI Studio](https://aistudio.google.com/)
- [Gemini API Documentation](https://ai.google.dev/docs)
- [Google Generative AI Node.js SDK](https://www.npmjs.com/package/@google/generative-ai)
- [Google Generative AI Python SDK](https://pypi.org/project/google-generativeai/)

## üìå ‡∏™‡∏£‡∏∏‡∏õ

Open-WebUI ‡πÅ‡∏•‡∏∞ Ollama ‡∏°‡∏≠‡∏ö‡∏≠‡∏¥‡∏™‡∏£‡∏∞‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (LLMs) ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á‡∏û‡∏≤‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô LLMs ‡πÅ‡∏ö‡∏ö local ‡∏î‡πâ‡∏ß‡∏¢ Ollama ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á AI ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà Open-WebUI ‡∏°‡∏≠‡∏ö‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢ ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á AI assistant ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏ó‡∏±‡πâ‡∏á‡∏¢‡∏±‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î
